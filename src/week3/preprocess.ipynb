{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from bpemb import BPEmb\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration copenlu--nlp_course_tydiqa-9ffd3d37cf2899c6\n",
      "Reusing dataset parquet (/home/lyk/.cache/huggingface/datasets/copenlu___parquet/copenlu--nlp_course_tydiqa-9ffd3d37cf2899c6/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "382609f4c95c4105875b19da98b5372b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"copenlu/answerable_tydiqa\")\n",
    "train_set = dataset[\"train\"]\n",
    "validation_set = dataset[\"validation\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_set = train_set.remove_columns([\"question_text\",\"document_title\",\"language\",\"annotations\",\"document_url\"])\n",
    "validation_set = validation_set.remove_columns([\"question_text\",\"document_title\",\"language\",\"annotations\",\"document_url\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# We'll use again the pretrained BP Embeddings and the corresponding tokenizer.\n",
    "\n",
    "bpemb_en = BPEmb(lang='en', dim=100, vs=25000)\n",
    "# Extract the embeddings and add a randomly initialized embedding for our extra [PAD] token\n",
    "pretrained_embeddings = np.concatenate([bpemb_en.emb.vectors, np.zeros(shape=(1,100))], axis=0)\n",
    "# Extract the vocab and add an extra [PAD] token\n",
    "vocabulary = bpemb_en.emb.index_to_key + ['[PAD]']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "block_size = 128\n",
    "def tokenizer(text):\n",
    "  return {'input_ids': bpemb_en.encode_ids_with_eos(text)}\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['document_plaintext'])\n",
    "\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of size block_size .\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        "
     ]
    },
    {
     "data": {
      "text/plain": "#0:   0%|          | 0/30 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67f008385f604d3d992a947d0b344f19"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "#2:   0%|          | 0/30 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c42e611862274e98900613829f8c8deb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "#1:   0%|          | 0/30 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d85879274ce4c5c9babb278e938dba8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "#3:   0%|          | 0/30 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b05b4a6bf4e34257b5e7df5a41176b9f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        "
     ]
    },
    {
     "data": {
      "text/plain": "#0:   0%|          | 0/30 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8781424451e6465fb66ceadf80fde088"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "#2:   0%|          | 0/30 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95150fd78d7d4fcc970090dcc5550b8f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "#1:   0%|          | 0/30 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "46060a0ab25840d9967f92696622e3f4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "#3:   0%|          | 0/30 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8843d8216d54e27acb7c147aeff8f29"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_tokenized_datasets = train_set.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"document_plaintext\"])\n",
    "train_datasets = train_tokenized_datasets.map(group_texts, batched=True, batch_size=1000, num_proc=4,)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       "
     ]
    },
    {
     "data": {
      "text/plain": "#0:   0%|          | 0/4 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1e60c5fa194b49cb983d3ef689c244b6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "text/plain": "#2:   0%|          | 0/4 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d4c6c1171442418d98a293be4a064d15"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "#1:   0%|          | 0/4 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "43d75cd1243148268074c69b17e4f5ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "#3:   0%|          | 0/4 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6aba8114103b489d8a9ac99dcd996904"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        "
     ]
    },
    {
     "data": {
      "text/plain": "#0:   0%|          | 0/4 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d389cdff0496435caa5d88ac0b6a6259"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "#1:   0%|          | 0/4 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "466bacd78733491a99939bbb286bc174"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "#2:   0%|          | 0/4 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21f45754282748cfa30059ede1864737"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "#3:   0%|          | 0/4 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce27c8637fef457d971d6d64ccf6ba2b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_tokenized_datasets = validation_set.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"document_plaintext\"])\n",
    "val_datasets = val_tokenized_datasets.map(group_texts, batched=True, batch_size=1000, num_proc=4,)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def get_document_dataset(dataset, block_size = 128):\n",
    "    document = []\n",
    "    for element in dataset:\n",
    "        document.append(element[\"document_plaintext\"].lower())\n",
    "    document_bpemb = [bpemb_en.encode_ids_with_eos(doc) for doc in document]\n",
    "    document_bpemb = sum(document_bpemb, [])\n",
    "    total_length = len(document_bpemb)\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    result = []\n",
    "    for i in range(0, total_length, block_size):\n",
    "        result.append(document_bpemb[i : i + block_size])\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "seq_len = 128\n",
    "def collate_batch_bilstm(dataset):\n",
    "    \"\"\"\n",
    "    Combines multiple data samples into a single batch\n",
    "    :param input_ids: The token input ids\n",
    "    :return: A tuple of tensors (input_ids, targets)\n",
    "    \"\"\"\n",
    "    input_ids = [i['input_ids'] for i in dataset]\n",
    "\n",
    "    input_lengths, padded_input = [], []\n",
    "    for sentence in input_ids:\n",
    "      sentence = sentence[:seq_len]\n",
    "      input_lengths.append(len(sentence) - 1)\n",
    "      sentence = sentence + [0] * (seq_len - len(sentence))\n",
    "      padded_input.append(sentence)\n",
    "\n",
    "    input_data = torch.tensor(padded_input)\n",
    "\n",
    "    # we don't use the last position as there isn't anything left for generation\n",
    "    input_ids = input_data[:, :-1]\n",
    "\n",
    "    # the target at each step is to generate the next word from the sequence\n",
    "    # so we shift the token ids with 1 position\n",
    "    targets = input_data[:, 1:].reshape(-1)\n",
    "\n",
    "    return input_ids, torch.tensor(input_lengths), targets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(train_datasets, batch_size=32, collate_fn=collate_batch_bilstm)\n",
    "valid_dl = torch.utils.data.DataLoader(val_datasets, batch_size=32, collate_fn=collate_batch_bilstm)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
