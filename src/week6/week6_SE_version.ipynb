{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1667517194305,"user":{"displayName":"Siyi Wu","userId":"06196688456534608936"},"user_tz":-480},"id":"Fmvvyytnu3pS","outputId":"b829f0a7-415b-4be1-8b84-49928ea1973f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Thu Nov  3 23:13:15 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   73C    P0    33W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["! nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3608,"status":"ok","timestamp":1667517197911,"user":{"displayName":"Siyi Wu","userId":"06196688456534608936"},"user_tz":-480},"id":"Xm3uRHQau0CK","outputId":"adcf1ab1-3248-4221-875e-43037bc04649"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.6.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: responses\u003c0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.1.0)\n","Requirement already satisfied: huggingface-hub\u003c1.0.0,\u003e=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.10.1)\n","Requirement already satisfied: pyarrow\u003e=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: dill\u003c0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n","Requirement already satisfied: tqdm\u003e=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: requests\u003e=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n","Requirement already satisfied: fsspec[http]\u003e=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.10.0)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003edatasets) (1.3.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003edatasets) (0.13.0)\n","Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003edatasets) (1.2.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003edatasets) (4.1.1)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003edatasets) (6.0.2)\n","Requirement already satisfied: async-timeout\u003c5.0,\u003e=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003edatasets) (4.0.2)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003edatasets) (1.8.1)\n","Requirement already satisfied: charset-normalizer\u003c3.0,\u003e=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003edatasets) (2.1.1)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-\u003edatasets) (22.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0.0,\u003e=0.2.0-\u003edatasets) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-\u003edatasets) (3.0.9)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (3.0.4)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests\u003e=2.19.0-\u003edatasets) (1.25.11)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003edatasets) (3.10.0)\n","Requirement already satisfied: python-dateutil\u003e=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas-\u003edatasets) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas-\u003edatasets) (2022.5)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil\u003e=2.7.3-\u003epandas-\u003edatasets) (1.15.0)\n"]}],"source":["! pip install datasets"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3819,"status":"ok","timestamp":1667517201728,"user":{"displayName":"Siyi Wu","userId":"06196688456534608936"},"user_tz":-480},"id":"FNkLsZy4u503","outputId":"f319a9b7-d806-43f6-d386-8a56cd821c33"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,\u003c0.14,\u003e=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.1)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.10.0-\u003etransformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers) (3.0.9)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers) (3.10.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2022.9.24)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (3.0.4)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (1.25.11)\n"]}],"source":["! pip install transformers"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5032,"status":"ok","timestamp":1667517206758,"user":{"displayName":"Siyi Wu","userId":"06196688456534608936"},"user_tz":-480},"id":"OKqK1nYJq-eC"},"outputs":[],"source":["from datasets import load_dataset\n","from datasets import load_metric\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer\n","from transformers import AutoModelForQuestionAnswering\n","from transformers import AutoConfig\n","from functools import partial\n","import torch\n","import torch.nn.functional as F\n","import random\n","import numpy as np\n","import collections\n","from tqdm.autonotebook import tqdm\n","from transformers import AdamW\n","from transformers import get_linear_schedule_with_warmup\n","from torch.optim.lr_scheduler import LambdaLR\n","from torch import nn\n","from collections import defaultdict, OrderedDict\n","from transformers import AdamW\n","from transformers import get_linear_schedule_with_warmup\n","from matplotlib import pyplot as plt"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1667517206758,"user":{"displayName":"Siyi Wu","userId":"06196688456534608936"},"user_tz":-480},"id":"me4D8NgwvFx7"},"outputs":[],"source":["MODEL_NAME = 'xlm-roberta-base'\n","\n","epochs = 3\n","batch_size = 8\n","lr = 2e-5\n","\n","weight_decay = 0.01\n","warmup_steps = 200\n","\n","train_language = [\"english\", \"japanese\", \"finnish\"]\n","val_language = [\"english\", \"japanese\", \"finnish\"]\n","squad_v2 = True"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1667517206759,"user":{"displayName":"Siyi Wu","userId":"06196688456534608936"},"user_tz":-480},"id":"-MLzbezM0U5-"},"outputs":[],"source":["def enforce_reproducibility(seed=42):\n","    # Sets seed manually for both CPU and CUDA\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    # For atomic operations there is currently \n","    # no simple way to enforce determinism, as\n","    # the order of parallel operations is not known.\n","    # CUDNN\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    # System based\n","    random.seed(seed)\n","    np.random.seed(seed)\n","\n","device = torch.device(\"cpu\")\n","if torch.cuda.is_available():\n","  device = torch.device(\"cuda\")\n","\n","enforce_reproducibility()"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":572,"status":"ok","timestamp":1667517207328,"user":{"displayName":"Siyi Wu","userId":"06196688456534608936"},"user_tz":-480},"id":"avtiLhCfPG5T","outputId":"356b433c-275d-466b-9e34-f50a586faf84"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"]}],"source":["# this is also equivalent to those 2 lines. I recommend going with that, unless you want more control over your code\n","from datasets import load_metric\n","compute_squad = load_metric(\"squad_v2\" if squad_v2 else \"squad\")"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":1287,"status":"ok","timestamp":1667517208613,"user":{"displayName":"Siyi Wu","userId":"06196688456534608936"},"user_tz":-480},"id":"019G8dSUPGTl"},"outputs":[],"source":["tk = AutoTokenizer.from_pretrained(MODEL_NAME)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1667517208613,"user":{"displayName":"Siyi Wu","userId":"06196688456534608936"},"user_tz":-480},"id":"07_KXsm1ymQX"},"outputs":[],"source":["def get_train_features(tk, samples):\n","    '''\n","    Tokenizes all of the text in the given samples, splittling inputs that are too long for our model\n","    across multiple features. Finds the token offsets of the answers, which serve as the labels for\n","    our inputs.\n","    '''\n","    batch = tk.batch_encode_plus(\n","        [[q, c] for q, c in zip(samples['question_text'], samples['document_plaintext'])],\n","        padding='max_length',\n","        truncation='only_second',\n","        stride=128,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True\n","    )\n","\n","    # Get a list which maps the input features index to their original index in the\n","    # samples list (for split inputs). E.g. if our batch size is 4 and the second sample\n","    # is split into 3 inputs because it is very large, sample_mapping would look like\n","    # [0, 1, 1, 1, 2, 3]\n","    sample_mapping = batch.pop('overflow_to_sample_mapping')\n","    # Get all of the character offsets for each token\n","    offset_mapping = batch.pop('offset_mapping')\n","\n","    # Store the start and end tokens\n","    batch['start_tokens'] = []\n","    batch['end_tokens'] = []\n","    # batch['no_answer_probability'] = []\n","\n","    # Iterate through all of the offsets\n","    for i, offsets in enumerate(offset_mapping):\n","        # Get the right sample by mapping it to its original index\n","        sample_idx = sample_mapping[i]\n","        # Get the sequence IDs to know where context starts so we can ignore question tokens\n","        sequence_ids = batch.sequence_ids(i)\n","\n","        # Get the start and end character positions of the answer\n","        ans = samples['annotations'][sample_idx]\n","        start_char = ans['answer_start'][0]\n","        end_char = start_char + len(ans['answer_text'][0])\n","        # while end_char \u003e 0 and (end_char \u003e= len(samples['context'][sample_idx]) or samples['context'][sample_idx][end_char] == ' '):\n","        #   end_char -= 1\n","\n","        # Start from the first token in the context, which can be found by going to the\n","        # first token where sequence_ids is 1\n","        start_token = 0\n","        no_answer_probability = 0\n","        while sequence_ids[start_token] != 1:\n","            start_token += 1\n","\n","        end_token = len(offsets) - 1\n","        while sequence_ids[end_token] != 1:\n","            end_token -= 1\n","\n","        # By default set it to the CLS token if the answer isn't in this input\n","        if start_char \u003c offsets[start_token][0] or end_char \u003e offsets[end_token][1]:\n","            start_token = 0\n","            end_token = 0\n","        # Otherwise find the correct token indices\n","        else:\n","            # Advance the start token index until we have passed the start character index\n","            while start_token \u003c len(offsets) and offsets[start_token][0] \u003c= start_char:\n","                start_token += 1\n","            start_token -= 1\n","\n","            # Decrease the end token index until we have passed the end character index\n","            while end_token \u003e= 0 and offsets[end_token][1] \u003e= end_char:\n","                end_token -= 1\n","            end_token += 1\n","        \n","        # no answer probability\n","        # if ans['answer_start'] == [-1]:\n","        #     no_answer_probability = 1\n","        # else:\n","        #     no_answer_probability = 0\n","\n","\n","        batch['start_tokens'].append(start_token)\n","        batch['end_tokens'].append(end_token)\n","        # batch['no_answer_probability'].append(no_answer_probability)\n","\n","    # batch['start_tokens'] = np.array(batch['start_tokens'])\n","    # batch['end_tokens'] = np.array(batch['end_tokens'])\n","\n","    return batch\n","\n","def collate_fn(inputs):\n","    '''\n","    Defines how to combine different samples in a batch\n","    '''\n","    input_ids = torch.tensor([i['input_ids'] for i in inputs])\n","    attention_mask = torch.tensor([i['attention_mask'] for i in inputs])\n","    start_tokens = torch.tensor([i['start_tokens'] for i in inputs])\n","    end_tokens = torch.tensor([i['end_tokens'] for i in inputs])\n","    # no_answer_probability = torch.tensor([i['no_answer_probability'] for i in inputs])\n","\n","    # Truncate to max length\n","    max_len = max(attention_mask.sum(-1))\n","    input_ids = input_ids[:, :max_len]\n","    attention_mask = attention_mask[:, :max_len]\n","\n","    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'start_tokens': start_tokens,\n","            'end_tokens': end_tokens}"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1667517208613,"user":{"displayName":"Siyi Wu","userId":"06196688456534608936"},"user_tz":-480},"id":"G0xYJhLXzOhX"},"outputs":[],"source":["def get_validation_features(tk, samples):\n","    # First, tokenize the text. We get the offsets and return overflowing sequences in\n","    # order to break up long sequences into multiple inputs. The offsets will help us\n","    # determine the original answer text\n","    batch = tk.batch_encode_plus(\n","        [[q, c] for q, c in zip(samples['question_text'], samples['document_plaintext'])],\n","        padding='max_length',\n","        truncation='only_second',\n","        stride=128,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True\n","    )\n","\n","    # We'll store the ID of the samples to calculate squad score\n","    batch['example_id'] = []\n","\n","    # batch['no_answer_probability'] = []\n","\n","    # The overflow sample map tells us which input each sample corresponds to\n","    sample_map = batch.pop('overflow_to_sample_mapping')\n","\n","    for i in range(len(batch['input_ids'])):\n","        # The sample index tells us which of the values in \"samples\" these features belong to\n","        sample_idx = sample_map[i]\n","        sequence_ids = batch.sequence_ids(i)\n","\n","        # Add the ID to map these features back to the correct sample\n","        batch['example_id'].append(samples['id'][sample_idx])\n","\n","        # Set offsets for non-context words to be None for ease of processing\n","        batch['offset_mapping'][i] = [o if sequence_ids[k] == 1 else None for k, o in\n","                                      enumerate(batch['offset_mapping'][i])]\n","\n","        # # no answer probability\n","        # ans = samples['annotations'][sample_idx]\n","        # if ans['answer_start'] == [-1]:\n","        #     no_answer_probability = 1\n","        # else:\n","        #     no_answer_probability = 0\n","\n","        # batch['no_answer_probability'].append(no_answer_probability)\n","\n","    return batch\n","\n","def val_collate_fn(inputs):\n","    input_ids = torch.tensor([i['input_ids'] for i in inputs])\n","    attention_mask = torch.tensor([i['attention_mask'] for i in inputs])\n","    # no_answer_probability = torch.tensor([i['no_answer_probability'] for i in inputs])\n","\n","\n","    # Truncate to max length\n","    max_len = max(attention_mask.sum(-1))\n","    input_ids = input_ids[:, :max_len]\n","    attention_mask = attention_mask[:, :max_len]\n","\n","    return {'input_ids': input_ids, 'attention_mask': attention_mask}"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1667517208614,"user":{"displayName":"Siyi Wu","userId":"06196688456534608936"},"user_tz":-480},"id":"8mV0GJjW2ivM"},"outputs":[],"source":["def predict(model: nn.Module, valid_dl: DataLoader):\n","    \"\"\"\n","    Evaluates the model on the given dataset\n","    :param model: The model under evaluation\n","    :param valid_dl: A `DataLoader` reading validation data\n","    :return: The accuracy of the model on the dataset\n","    \"\"\"\n","    # VERY IMPORTANT: Put your model in \"eval\" mode -- this disables things like\n","    # layer normalization and dropout\n","    model.eval()\n","    start_logits_all = []\n","    end_logits_all = []\n","    # no_answer_probability_logits_all = []\n","\n","    # ALSO IMPORTANT: Don't accumulate gradients during this process\n","    with torch.no_grad():\n","        for batch in tqdm(valid_dl, desc='Evaluation'):\n","            batch = {b: batch[b].to('cuda') for b in batch}\n","\n","            # Pass the inputs through the model, get the current loss and logits\n","            outputs = model(\n","                input_ids=batch['input_ids'],\n","                attention_mask=batch['attention_mask']\n","            )\n","            # Store the \"start\" class logits and \"end\" class logits for every token in the input\n","            start_logits_all.extend(list(outputs['start_logits'].detach().cpu().numpy()))\n","            end_logits_all.extend(list(outputs['end_logits'].detach().cpu().numpy()))\n","            # no_answer_probability_logits_all.extend(list(F.sigmoid(classify_labels[:,1]).detach().cpu().numpy()))            \n","\n","        return start_logits_all, end_logits_all\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1667517208614,"user":{"displayName":"Siyi Wu","userId":"06196688456534608936"},"user_tz":-480},"id":"8y6SZ-4TXCX5"},"outputs":[],"source":["def post_process_predictions(examples, dataset, logits, num_possible_answers=20, max_answer_length=30):\n","    all_start_logits, all_end_logits = logits\n","    \n","    # Build a map from example to its corresponding features. This will allow us to index from\n","    # sample ID to all of the features for that sample (in case they were split up due to long input)\n","    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n","    features_per_example = defaultdict(list)\n","    for i, feature in enumerate(dataset):\n","        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n","\n","    # Create somewhere to store our predictions\n","    predictions = OrderedDict()\n","\n","    # Iterate through each sample in the dataset\n","    for j, sample in enumerate(tqdm(examples)):\n","\n","        # Get the feature indices (all of the features split across the batch)\n","        feature_indices = features_per_example[j]\n","        # Get the original context which predumably has the answer text\n","        context = sample['document_plaintext']\n","\n","        preds = []\n","        # Iterate through all of the features\n","        for ft_idx in feature_indices:\n","\n","            # Get the start and end answer logits for this input\n","            start_logits = all_start_logits[ft_idx]\n","            end_logits = all_end_logits[ft_idx]\n","            # no_answer_probability_logits = all_no_answer_probability_logits[ft_idx]\n","\n","            # Get the offsets to map token indices to character indices\n","            offset_mapping = dataset[ft_idx]['offset_mapping']\n","\n","            # Sort the logits and take the top N\n","            start_indices = np.argsort(start_logits)[::-1][:num_possible_answers]\n","            end_indices = np.argsort(end_logits)[::-1][:num_possible_answers]\n","\n","            # Iterate through start and end indices\n","            for start_index in start_indices:\n","                for end_index in end_indices:\n","\n","                    # Ignore this combination if either the indices are not in the context\n","                    if start_index \u003e= len(offset_mapping) or end_index \u003e= len(offset_mapping) or offset_mapping[\n","                        start_index] is None or offset_mapping[end_index] is None:\n","                        continue\n","\n","                    # Also ignore if the start index is greater than the end index of the number of tokens\n","                    # is greater than some specified threshold\n","                    if start_index \u003e end_index or end_index - start_index + 1 \u003e max_answer_length:\n","                        continue\n","\n","                    ans_text = context[offset_mapping[start_index][0]:offset_mapping[end_index][1]]\n","                    preds.append({\n","                        'score': start_logits[start_index] + end_logits[end_index],\n","                        'text': ans_text\n","                    })\n","\n","        if len(preds) \u003e 0:\n","            # Sort by score to get the top answer\n","            answer = sorted(preds, key=lambda x: x['score'], reverse=True)[0]\n","        else:\n","            answer = {'score': 0.0, 'text': \"\"}\n","\n","        predictions[sample['id']] = answer['text']\n","    return predictions"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1667517208614,"user":{"displayName":"Siyi Wu","userId":"06196688456534608936"},"user_tz":-480},"id":"hX0ozeoSFUfI"},"outputs":[],"source":["def postprocess_qa_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 30):\n","    all_start_logits, all_end_logits = raw_predictions\n","    # Build a map example to its corresponding features.\n","    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n","    features_per_example = collections.defaultdict(list)\n","    for i, feature in enumerate(features):\n","        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n","\n","    # The dictionaries we have to fill.\n","    predictions = collections.OrderedDict()\n","\n","    # Logging.\n","    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n","\n","    # Let's loop over all the examples!\n","    for example_index, example in enumerate(tqdm(examples)):\n","        # Those are the indices of the features associated to the current example.\n","        feature_indices = features_per_example[example_index]\n","\n","        min_null_score = None # Only used if squad_v2 is True.\n","        valid_answers = []\n","        \n","        context = example[\"document_plaintext\"]\n","        # Looping through all the features associated to the current example.\n","        for feature_index in feature_indices:\n","            # We grab the predictions of the model for this feature.\n","            start_logits = all_start_logits[feature_index]\n","            end_logits = all_end_logits[feature_index]\n","            # This is what will allow us to map some the positions in our logits to span of texts in the original\n","            # context.\n","            offset_mapping = features[feature_index][\"offset_mapping\"]\n","\n","            # Update minimum null prediction.\n","            cls_index = features[feature_index][\"input_ids\"].index(tk.cls_token_id)\n","            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n","            if min_null_score is None or min_null_score \u003c feature_null_score:\n","                min_null_score = feature_null_score\n","\n","            # Go through all possibilities for the `n_best_size` greater start and end logits.\n","            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n","            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n","            for start_index in start_indexes:\n","                for end_index in end_indexes:\n","                    # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n","                    # to part of the input_ids that are not in the context.\n","                    if (\n","                        start_index \u003e= len(offset_mapping)\n","                        or end_index \u003e= len(offset_mapping)\n","                        or offset_mapping[start_index] is None\n","                        or offset_mapping[end_index] is None\n","                    ):\n","                        continue\n","                    # Don't consider answers with a length that is either \u003c 0 or \u003e max_answer_length.\n","                    if end_index \u003c start_index or end_index - start_index + 1 \u003e max_answer_length:\n","                        continue\n","\n","                    start_char = offset_mapping[start_index][0]\n","                    end_char = offset_mapping[end_index][1]\n","                    valid_answers.append(\n","                        {\n","                            \"score\": start_logits[start_index] + end_logits[end_index],\n","                            \"text\": context[start_char: end_char]\n","                        }\n","                    )\n","        \n","        if len(valid_answers) \u003e 0:\n","            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n","        else:\n","            # In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid\n","            # failure.\n","            best_answer = {\"text\": \"\", \"score\": 0.0}\n","        \n","        # Let's pick our final answer: the best one or the null answer (only for squad_v2)\n","        answer = best_answer[\"text\"] if best_answer[\"score\"] \u003e min_null_score else \"\"\n","        predictions[example[\"id\"]] = answer\n","\n","    return predictions"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1667517208614,"user":{"displayName":"Siyi Wu","userId":"06196688456534608936"},"user_tz":-480},"id":"R9eekuw7zRjZ"},"outputs":[],"source":["def getLanguageDataSet(data, language):\n","    def printAndL(x):\n","        return x[\"language\"] in language\n","\n","    return data.filter(printAndL)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1667517208614,"user":{"displayName":"Siyi Wu","userId":"06196688456534608936"},"user_tz":-480},"id":"p97I_2ufzjC1"},"outputs":[],"source":["def process_train_data(language):\n","    dataset = load_dataset(\"copenlu/answerable_tydiqa\")\n","    dataset = getLanguageDataSet(dataset, language)['train']\n","    dataset = dataset.remove_columns(\"language\")\n","    dataset = dataset.remove_columns(\"document_url\")\n","\n","    tokenized_dataset = dataset.map(partial(get_train_features, tk), batched=True, remove_columns=dataset.column_names)\n","    return tokenized_dataset\n","\n","def process_validation_data(language):\n","    dataset = load_dataset(\"copenlu/answerable_tydiqa\")\n","    dataset = getLanguageDataSet(dataset, language)['validation']\n","    dataset = dataset.remove_columns(\"language\")\n","    dataset = dataset.remove_columns(\"document_url\")\n","    ids = [i for i in range(len(dataset['question_text']))]\n","    dataset = dataset.add_column('id',ids)\n","\n","    tokenized_dataset = dataset.map(partial(get_validation_features, tk), batched=True, remove_columns=dataset.column_names)\n","    return tokenized_dataset"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1667517208614,"user":{"displayName":"Siyi Wu","userId":"06196688456534608936"},"user_tz":-480},"id":"ztZaUGvdzoQY"},"outputs":[],"source":["def train(\n","    model: nn.Module, \n","    train_dl: DataLoader, \n","    optimizer: torch.optim.Optimizer, \n","    schedule: LambdaLR,\n","    n_epochs: int, \n","    device: torch.device\n","):\n","  \"\"\"\n","  The main training loop which will optimize a given model on a given dataset\n","  :param model: The model being optimized\n","  :param train_dl: The training dataset\n","  :param optimizer: The optimizer used to update the model parameters\n","  :param n_epochs: Number of epochs to train for\n","  :param device: The device to train on\n","  \"\"\"\n","\n","  # Keep track of the loss and best accuracy\n","  losses = []\n","  best_acc = 0.0\n","  pcounter = 0\n","\n","  # Iterate through epochs\n","  for ep in range(n_epochs):\n","\n","    loss_epoch = []\n","\n","    #Iterate through each batch in the dataloader\n","    for batch in tqdm(train_dl):\n","      # VERY IMPORTANT: Make sure the model is in training mode, which turns on \n","      # things like dropout and layer normalization\n","      model.train()\n","\n","      # VERY IMPORTANT: zero out all of the gradients on each iteration -- PyTorch\n","      # keeps track of these dynamically in its computation graph so you need to explicitly\n","      # zero them out\n","      optimizer.zero_grad()\n","\n","      # Place each tensor on the GPU\n","      batch = {b: batch[b].to(device) for b in batch}\n","\n","      # Pass the inputs through the model, get the current loss and logits\n","      outputs = model(\n","          input_ids=batch['input_ids'],\n","          attention_mask=batch['attention_mask'],\n","          start_positions=batch['start_tokens'],\n","          end_positions=batch['end_tokens']\n","      )\n","\n","      loss = outputs['loss']\n","      losses.append(loss.item())\n","      loss_epoch.append(loss.item())\n","      \n","      # Calculate all of the gradients and weight updates for the model\n","      loss.backward()\n","\n","      # Optional: clip gradients\n","      #torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","      # Finally, update the weights of the model and advance the LR schedule\n","      optimizer.step()\n","      scheduler.step()\n","      #gc.collect()\n","  return losses"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"executionInfo":{"elapsed":34101,"status":"ok","timestamp":1667517242711,"user":{"displayName":"Siyi Wu","userId":"06196688456534608936"},"user_tz":-480},"id":"NBAjcNqNz7aH","outputId":"32852010-5e8b-4db2-f6fb-8d4d0dbf287f"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:datasets.builder:Using custom data configuration copenlu--nlp_course_tydiqa-9ffd3d37cf2899c6\n","WARNING:datasets.builder:Found cached dataset parquet (/root/.cache/huggingface/datasets/copenlu___parquet/copenlu--nlp_course_tydiqa-9ffd3d37cf2899c6/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca0815c6c20145f09d8120ff50cb00bf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6e1f65293e3a4e05937cc32691359860","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/117 [00:00\u003c?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4a92c876ac224eb4852a9e3a157375b2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/14 [00:00\u003c?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"81fb74f97592476ea8541b7fffad5d1b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/30 [00:00\u003c?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenized_train_dataset = process_train_data(train_language)\n","train_dl = DataLoader(tokenized_train_dataset, collate_fn=collate_fn, shuffle=True, batch_size=batch_size)\n"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5791,"status":"ok","timestamp":1667517248493,"user":{"displayName":"Siyi Wu","userId":"06196688456534608936"},"user_tz":-480},"id":"JX9Nyvoj-2hj","outputId":"bc272575-3db4-441b-dbae-9aa09e1c6c20"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForQuestionAnswering: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias']\n","- This IS expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaForQuestionAnswering were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["XLMRobertaForQuestionAnswering(\n","  (roberta): XLMRobertaModel(\n","    (embeddings): XLMRobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): XLMRobertaEncoder(\n","      (layer): ModuleList(\n","        (0): XLMRobertaLayer(\n","          (attention): XLMRobertaAttention(\n","            (self): XLMRobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): XLMRobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): XLMRobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): XLMRobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): XLMRobertaLayer(\n","          (attention): XLMRobertaAttention(\n","            (self): XLMRobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): XLMRobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): XLMRobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): XLMRobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): XLMRobertaLayer(\n","          (attention): XLMRobertaAttention(\n","            (self): XLMRobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): XLMRobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): XLMRobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): XLMRobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): XLMRobertaLayer(\n","          (attention): XLMRobertaAttention(\n","            (self): XLMRobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): XLMRobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): XLMRobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): XLMRobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): XLMRobertaLayer(\n","          (attention): XLMRobertaAttention(\n","            (self): XLMRobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): XLMRobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): XLMRobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): XLMRobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): XLMRobertaLayer(\n","          (attention): XLMRobertaAttention(\n","            (self): XLMRobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): XLMRobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): XLMRobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): XLMRobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): XLMRobertaLayer(\n","          (attention): XLMRobertaAttention(\n","            (self): XLMRobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): XLMRobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): XLMRobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): XLMRobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): XLMRobertaLayer(\n","          (attention): XLMRobertaAttention(\n","            (self): XLMRobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): XLMRobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): XLMRobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): XLMRobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): XLMRobertaLayer(\n","          (attention): XLMRobertaAttention(\n","            (self): XLMRobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): XLMRobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): XLMRobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): XLMRobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): XLMRobertaLayer(\n","          (attention): XLMRobertaAttention(\n","            (self): XLMRobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): XLMRobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): XLMRobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): XLMRobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): XLMRobertaLayer(\n","          (attention): XLMRobertaAttention(\n","            (self): XLMRobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): XLMRobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): XLMRobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): XLMRobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): XLMRobertaLayer(\n","          (attention): XLMRobertaAttention(\n","            (self): XLMRobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): XLMRobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): XLMRobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): XLMRobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["model = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME).to(device)\n","\n","model"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1667517248494,"user":{"displayName":"Siyi Wu","userId":"06196688456534608936"},"user_tz":-480},"id":"ps0bygqe4Ew8","outputId":"62993f09-1db4-4341-df2f-7238b2b904b5"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}],"source":["no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","     'weight_decay': weight_decay},\n","    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer,\n","    warmup_steps,\n","    epochs * len(train_dl)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":113},"id":"feQQFaYq4n8-"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"09fffbe41a014c4bac7017c7ecd13eb6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3846 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aaea64c9593140b4959ce01ad096368d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3846 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e9ba16b9b1bc4591a991a57fe789c564","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3846 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["losses = train(\n","    model,\n","    train_dl,\n","    optimizer,\n","    scheduler,\n","    epochs,\n","    device\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"AFW-pAQz9iaR"},"outputs":[{"data":{"text/plain":["[\u003cmatplotlib.lines.Line2D at 0x7fac36012690\u003e]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["plt.cla()\n","plt.plot(losses)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"EUxb4yGC4qGK"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:datasets.builder:Using custom data configuration copenlu--nlp_course_tydiqa-9ffd3d37cf2899c6\n","WARNING:datasets.builder:Found cached dataset parquet (/root/.cache/huggingface/datasets/copenlu___parquet/copenlu--nlp_course_tydiqa-9ffd3d37cf2899c6/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"310b5c6b29b44ec590f0a0f671787857","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/copenlu___parquet/copenlu--nlp_course_tydiqa-9ffd3d37cf2899c6/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-0eeb3d4b6f087e42.arrow\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/copenlu___parquet/copenlu--nlp_course_tydiqa-9ffd3d37cf2899c6/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-352844a60b957ece.arrow\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cb35a19ece774da083d481eb38a9ea43","version_major":2,"version_minor":0},"text/plain":["Flattening the indices:   0%|          | 0/4 [00:00\u003c?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"92e892293c1c48dca14a037e8ff731d5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/4 [00:00\u003c?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["WARNING:datasets.builder:Using custom data configuration copenlu--nlp_course_tydiqa-9ffd3d37cf2899c6\n","WARNING:datasets.builder:Found cached dataset parquet (/root/.cache/huggingface/datasets/copenlu___parquet/copenlu--nlp_course_tydiqa-9ffd3d37cf2899c6/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da79306e6e964d15ab0194c75a4139db","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/copenlu___parquet/copenlu--nlp_course_tydiqa-9ffd3d37cf2899c6/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-0eeb3d4b6f087e42.arrow\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/copenlu___parquet/copenlu--nlp_course_tydiqa-9ffd3d37cf2899c6/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-352844a60b957ece.arrow\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9048fcd183c48d59c822ad62134e96f","version_major":2,"version_minor":0},"text/plain":["Flattening the indices:   0%|          | 0/4 [00:00\u003c?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenized_val_dataset = process_validation_data(val_language)\n","example_val = load_dataset(\"copenlu/answerable_tydiqa\")\n","example_val = getLanguageDataSet(example_val, val_language)['validation']\n","\n","ids = [i for i in range(len(example_val['question_text']))]\n","example_val = example_val.add_column('id',ids)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"3Ri512-B6lv8"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"03c3b50e2c8c4e60986074b54658d4f3","version_major":2,"version_minor":0},"text/plain":["Evaluation:   0%|          | 0/473 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["val_dl = DataLoader(tokenized_val_dataset, collate_fn=val_collate_fn, shuffle=False, batch_size=batch_size)\n","logits = predict(model, val_dl)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"SVy_c5pnXUiB"},"outputs":[],"source":["id_list = []\n","answer_list = []\n","\n","for example in example_val:\n","    id_list.append(example['id'])\n","    answer_list.append(example['annotations'])\n","\n","for mydict in answer_list:\n","    mydict['text'] = mydict.pop('answer_text')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"SGoNFpnB66nX"},"outputs":[{"name":"stdout","output_type":"stream","text":["Post-processing 3712 example predictions split into 3779 features.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a0e5d6d78c184fee90e9573ca4557762","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3712 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["if squad_v2:\n","    predictions = postprocess_qa_predictions(example_val, tokenized_val_dataset, logits)\n","else:\n","    predictions = post_process_predictions(example_val, tokenized_val_dataset, logits)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"cXKbsIpDGf37"},"outputs":[],"source":["# formatted_predictions = []\n","# for k, v in predictions.items():\n","#       if v ==  '':\n","#           formatted_predictions.append({'id': k, 'prediction_text': v, 'no_answer_probability': 0.0})\n","#       else:\n","#           formatted_predictions.append({'id': k, 'prediction_text': v, 'no_answer_probability': 1.0})\n","\n","if squad_v2:\n","    formatted_predictions = [{\"id\": k, \"prediction_text\": v, \"no_answer_probability\": 0.0} for k, v in predictions.items()]\n","else:\n","    formatted_predictions = [{'id': k, 'prediction_text': v} for k,v in predictions.items()]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"pyczt4-ZHJm1"},"outputs":[],"source":["gold = [{'id': id_list[i], 'answers': answer_list[i]} for i in range(len(id_list))]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"nVoM1xCkIUP8"},"outputs":[{"data":{"text/plain":["{'exact': 72.06357758620689,\n"," 'f1': 76.16937680414289,\n"," 'total': 3712,\n"," 'HasAns_exact': 72.06357758620689,\n"," 'HasAns_f1': 76.16937680414289,\n"," 'HasAns_total': 3712,\n"," 'best_exact': 72.06357758620689,\n"," 'best_exact_thresh': 0.0,\n"," 'best_f1': 76.16937680414289,\n"," 'best_f1_thresh': 0.0}"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["compute_squad.compute(references=gold, predictions=formatted_predictions)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"dleWqOb-ic6N"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"01daf59935c64f10817a44e4791dcf71":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0295f1ec32cb4366987fa3abe2e94474":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_41d7578ef76b420f9d66a6abd1d87f76","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_add7c264aea74cd9b204b574822b61bc","value":29}},"06a1d65098624cbca0c564aa94691fdd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06a9105ae73f488abc71e5eb9680f447":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"09fffbe41a014c4bac7017c7ecd13eb6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fb63fcda05124d82a64f3ad09a5929e5","IPY_MODEL_507fbd0c2fef4b4d9a95bb7f119a18bd","IPY_MODEL_49423894608f46009a2b90e239974352"],"layout":"IPY_MODEL_ee56aad539104b45a461607c73801cb5"}},"0a6fdf4d32dc4ed086b662aa65b607b7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0dee1842beed461492d1769b8a5dd5b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12efe52cfb5140e090056dace6787cc6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1569c609f4064bd29c0ab89dd30dc479":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"180936e80d514907b53243e36c9b5138":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1daf7b3b83474c59b4e599af504a6332":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f88ebebf79e408288d80380e40eb3c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25a16590812a49259bbb6ebb36babe61":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"262ba9fabb0c44a0b08ccd1b38814bc6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26ede56e98ec4a1695ae864df05208c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12efe52cfb5140e090056dace6787cc6","placeholder":"​","style":"IPY_MODEL_ecc449358bc543c2ba9ba86e5b236603","value":"100%"}},"27fad4815dc4485bb51c09b5a23cf518":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b29d0aad5534345b47b6aa26019cf70":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cf6e8c4f17540489429d5e7719e0331":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_262ba9fabb0c44a0b08ccd1b38814bc6","placeholder":"​","style":"IPY_MODEL_3dbdb4a032614d99baa12f2040987528","value":" 93%"}},"3dbdb4a032614d99baa12f2040987528":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40af9ca18ba24ad79c5499116d81578f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"416928bea85b4861bdf08ec1e73f149b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4196362ddfd741668ec9e21b93c293ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb71b9336c454de9abb87a8b7f188e54","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5af15b48d32144f5992f9bec85bd42a7","value":2}},"41d7578ef76b420f9d66a6abd1d87f76":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49423894608f46009a2b90e239974352":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef1164fcc48b4eb492f6521c273d7c30","placeholder":"​","style":"IPY_MODEL_5006a395f24f4e6ca8dc4e1346fc51ec","value":" 3846/3846 [38:44\u0026lt;00:00,  1.87it/s]"}},"4a92c876ac224eb4852a9e3a157375b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3cf6e8c4f17540489429d5e7719e0331","IPY_MODEL_fe50580874544302b7f56eb1fb3d148d","IPY_MODEL_ce87202fe5544865a11d1f276b5c8ef6"],"layout":"IPY_MODEL_700fdc32db644093add3726049e9943e"}},"4b53d2f548794f2a8ae4a2d892abbd7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5006a395f24f4e6ca8dc4e1346fc51ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"507fbd0c2fef4b4d9a95bb7f119a18bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b04489fb59954bb19120d25befe1b210","max":3846,"min":0,"orientation":"horizontal","style":"IPY_MODEL_06a9105ae73f488abc71e5eb9680f447","value":3846}},"5af15b48d32144f5992f9bec85bd42a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6118f62cc8c640c08c54bd59334c7cd9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"687f1ad7a95044a1b34e946fc5df009a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a70fb6bacca40408836b8f2adb6926c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_06a1d65098624cbca0c564aa94691fdd","max":117,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4b53d2f548794f2a8ae4a2d892abbd7e","value":116}},"6e1f65293e3a4e05937cc32691359860":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_911fc34bcf054bbe82779c68aa6a3416","IPY_MODEL_6a70fb6bacca40408836b8f2adb6926c","IPY_MODEL_c610aff1be554e66ad1c9beb709b3a3e"],"layout":"IPY_MODEL_c5c4122967204ab6b774ebaaa1c8f85e"}},"700fdc32db644093add3726049e9943e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"705febe8be4c4814bfaf60ad1efb5eac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7262f95ea4ec4166a958485d35df5f5e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"74815081595f4cd0a0786bf42e61fadb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c23d6b84dad4a61b2ca881bf4de5f31":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb3a378c97ea4c8698303db6aa484121","placeholder":"​","style":"IPY_MODEL_fe89c9dbea164095b3709d88d10c5899","value":" 97%"}},"7e706ebe002844b5a7470920d9764aac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1daf7b3b83474c59b4e599af504a6332","placeholder":"​","style":"IPY_MODEL_01daf59935c64f10817a44e4791dcf71","value":" 29/30 [00:27\u0026lt;00:00,  1.73ba/s]"}},"81fb74f97592476ea8541b7fffad5d1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7c23d6b84dad4a61b2ca881bf4de5f31","IPY_MODEL_0295f1ec32cb4366987fa3abe2e94474","IPY_MODEL_7e706ebe002844b5a7470920d9764aac"],"layout":"IPY_MODEL_1569c609f4064bd29c0ab89dd30dc479"}},"8359151aba7d4d8ba14b84b9b346d06d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b94a53cad8c40a99b59a99c213ff2c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d45f9f7e9bf425a96b20b3760f995dd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8efd61fde25d4fa0b1bb8039febca880":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"911fc34bcf054bbe82779c68aa6a3416":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_687f1ad7a95044a1b34e946fc5df009a","placeholder":"​","style":"IPY_MODEL_0dee1842beed461492d1769b8a5dd5b5","value":" 99%"}},"989644179f224a2083fb10a53f0c108d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfc7491fb445403d9097f2afce6a092f","placeholder":"​","style":"IPY_MODEL_416928bea85b4861bdf08ec1e73f149b","value":"100%"}},"9f52c1cf22ad4d38981424b5a1711282":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aab6a76677f0462ba0498966f8d3aaa4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aaea64c9593140b4959ce01ad096368d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_989644179f224a2083fb10a53f0c108d","IPY_MODEL_cf87651e7ede4bd2a963544540906fd2","IPY_MODEL_de8c75505b4b47eaa5e649141182155f"],"layout":"IPY_MODEL_b58d3220de9748e8a36a3bc23a85d296"}},"add7c264aea74cd9b204b574822b61bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b04489fb59954bb19120d25befe1b210":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b58d3220de9748e8a36a3bc23a85d296":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb3a378c97ea4c8698303db6aa484121":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf0b1abe9ee74a1892bdea500848e4d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c35908eb0aea4827a1f4152c71f71d07":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4fcd634f76b4bd6a7548e852cc84c94","placeholder":"​","style":"IPY_MODEL_1f88ebebf79e408288d80380e40eb3c3","value":" 2/2 [00:00\u0026lt;00:00, 58.35it/s]"}},"c5c4122967204ab6b774ebaaa1c8f85e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c610aff1be554e66ad1c9beb709b3a3e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e306252c600c471f889445f0a35be535","placeholder":"​","style":"IPY_MODEL_74815081595f4cd0a0786bf42e61fadb","value":" 116/117 [00:04\u0026lt;00:00, 22.99ba/s]"}},"ca0815c6c20145f09d8120ff50cb00bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_26ede56e98ec4a1695ae864df05208c9","IPY_MODEL_4196362ddfd741668ec9e21b93c293ab","IPY_MODEL_c35908eb0aea4827a1f4152c71f71d07"],"layout":"IPY_MODEL_0a6fdf4d32dc4ed086b662aa65b607b7"}},"ce87202fe5544865a11d1f276b5c8ef6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b29d0aad5534345b47b6aa26019cf70","placeholder":"​","style":"IPY_MODEL_8b94a53cad8c40a99b59a99c213ff2c6","value":" 13/14 [00:00\u0026lt;00:00, 20.97ba/s]"}},"cf87651e7ede4bd2a963544540906fd2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6118f62cc8c640c08c54bd59334c7cd9","max":3846,"min":0,"orientation":"horizontal","style":"IPY_MODEL_40af9ca18ba24ad79c5499116d81578f","value":3846}},"d0726e26298f4770ad2162cc7201a3ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_8efd61fde25d4fa0b1bb8039febca880","max":3846,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bf0b1abe9ee74a1892bdea500848e4d5","value":2101}},"ddeb465c1db746cfbb276c621b483556":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de8c75505b4b47eaa5e649141182155f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f52c1cf22ad4d38981424b5a1711282","placeholder":"​","style":"IPY_MODEL_27fad4815dc4485bb51c09b5a23cf518","value":" 3846/3846 [39:04\u0026lt;00:00,  1.63it/s]"}},"dfc7491fb445403d9097f2afce6a092f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e306252c600c471f889445f0a35be535":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9ba16b9b1bc4591a991a57fe789c564":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f227fb90d83946429636906630afb891","IPY_MODEL_d0726e26298f4770ad2162cc7201a3ef","IPY_MODEL_f37af9757d0a4df2b73f82baf0c095d6"],"layout":"IPY_MODEL_25a16590812a49259bbb6ebb36babe61"}},"eb71b9336c454de9abb87a8b7f188e54":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecc449358bc543c2ba9ba86e5b236603":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee0fccf26e5e46c5b0d9b50ccd7954b6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee56aad539104b45a461607c73801cb5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef1164fcc48b4eb492f6521c273d7c30":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f227fb90d83946429636906630afb891":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee0fccf26e5e46c5b0d9b50ccd7954b6","placeholder":"​","style":"IPY_MODEL_7262f95ea4ec4166a958485d35df5f5e","value":" 55%"}},"f37af9757d0a4df2b73f82baf0c095d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_180936e80d514907b53243e36c9b5138","placeholder":"​","style":"IPY_MODEL_8359151aba7d4d8ba14b84b9b346d06d","value":" 2101/3846 [21:14\u0026lt;19:12,  1.51it/s]"}},"f4fcd634f76b4bd6a7548e852cc84c94":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb63fcda05124d82a64f3ad09a5929e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d45f9f7e9bf425a96b20b3760f995dd","placeholder":"​","style":"IPY_MODEL_705febe8be4c4814bfaf60ad1efb5eac","value":"100%"}},"fe50580874544302b7f56eb1fb3d148d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_ddeb465c1db746cfbb276c621b483556","max":14,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aab6a76677f0462ba0498966f8d3aaa4","value":13}},"fe89c9dbea164095b3709d88d10c5899":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}